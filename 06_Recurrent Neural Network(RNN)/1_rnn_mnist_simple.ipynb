{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sequence classification with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages imported\n",
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "mnist loaded\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "print (\"packages imported\")\n",
    "\n",
    "mnist = input_data.read_data_sets('../MNIST_data/', one_hot=True)\n",
    "train_imgs, train_labels, test_imgs, test_labels \\\n",
    "= mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
    "n_train, n_test, dim, n_classes \\\n",
    "= train_imgs.shape[0], test_imgs[0], train_imgs.shape[1], train_labels.shape[1]\n",
    "print (\"mnist loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will treat the MNIST image $\\in \\mathcal{R}^{28 \\times 28}$ as $28$ sequences of a vector $\\mathbf{x} \\in \\mathcal{R}^{28}$. \n",
    "## Our simple RNN consists of  \n",
    "1. One input layer which converts a $28$ dimensional input to an $128$ dimensional hidden layer, \n",
    "2. One intermediate recurrent neural network (LSTM) \n",
    "3. One output layer which converts an $128$ dimensional output of the LSTM to $10$ dimensional output indicating a class label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/etc/rnn_input3.jpg\" width=\"700\" height=\"400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contruct a RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/liuzhiyang/.conda/envs/jupyter/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "dim_input = 28\n",
    "dim_hidden = 128\n",
    "dim_output = n_classes\n",
    "n_step = 28\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([dim_input, dim_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([dim_hidden, dim_output]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([dim_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([dim_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network ready\n"
     ]
    }
   ],
   "source": [
    "def _RNN(_x, _istate, _w, _b, _nsteps, _name):\n",
    "    # 1. premute input from [batch_size, n_step, dim_input]\n",
    "    # => [n_steps, batch_size, dim_input]\n",
    "    _x = tf.transpose(_x, [1, 0, 2])\n",
    "    # 2. reshape input to [n_step * batch_size , dim_input]\n",
    "    _x = tf.reshape(_x, [-1, dim_input])\n",
    "    # 3. input layer => hidden layer\n",
    "    _h = tf.matmul(_x, _w['hidden']) + b['hidden']\n",
    "    # 4. splite data to 'n_step' chuncks, an i-th chunck indicates i-th batch data\n",
    "    _h_split = tf.split(0, _nsteps, _h)\n",
    "    # 5. get lstm's final output (_LSTM_0) and state (_LSTM_S)\n",
    "    #    Both _LSTM_O and _LSTM_S consist of 'batchsize' elements\n",
    "    #    Only _LSTM_O will be used to predict the output.\n",
    "    with tf.variable_scope(_name):\n",
    "        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(dim_hidden, forget_bias=1.0)\n",
    "        _LSTM_O, _LSTM_S = tf.nn.rnn(lstm_cell, _h_split, initial_state = _istate)\n",
    "    # 6. output\n",
    "    _O = tf.add(tf.matmul(_LSTM_O[-1], _w['out']), _b['out'])\n",
    "    # return \n",
    "    return {\n",
    "        'X': _x, 'h': _h, 'hsplit': _h_split, \n",
    "        'LSTM_O': _LSTM_O, '_LSTM_S': _LSTM_S, 'O': _O\n",
    "    }\n",
    "print(\"network ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter]",
   "language": "python",
   "name": "conda-env-jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
